// hooks.c â€” EPT Hook Framework Implementation
// OmbraHypervisor
//
// =============================================================================
// CRITICAL REQUIREMENT: Identity Mapped Physical Memory
// =============================================================================
//
// This hook framework REQUIRES that the hypervisor has identity-mapped all
// guest physical memory in its own address space (HVA == HPA).
//
// Background:
//   - EPT translates Guest Physical Address (GPA) -> Host Physical Address (HPA)
//   - Guest page tables translate Guest Virtual (GVA) -> GPA
//   - Hypervisor page tables translate Host Virtual (HVA) -> HPA
//
// The hypervisor runs with its own CR3 (host page tables), NOT the guest's CR3.
// When we hook guest code, we need to:
//   1. Read the original guest physical page (need HPA -> HVA translation)
//   2. Copy it to a shadow page
//   3. Modify the shadow page with our hook code
//   4. Update EPT to point executes to the shadow page
//
// Without identity mapping, we cannot access guest physical pages from the
// hypervisor context. We would need:
//   - On-demand mapping via hypervisor page tables
//   - A translation cache for frequently accessed pages
//   - Special MMIO windows for physical memory access
//
// Current implementation: Assumes identity mapping with validation checks
// Production implementation: Would require proper HPA->HVA translation layer
//
// =============================================================================

#include "hooks.h"
#include "ept.h"
#include "vmx.h"
#include "debug.h"
#include "../shared/ept_defs.h"

// =============================================================================
// Global Hook Manager Instance
// =============================================================================

HOOK_MANAGER g_HookManager = {0};

// =============================================================================
// Internal Helpers
// =============================================================================

static void ZeroMemory(void* ptr, U64 size) {
    U8* p = (U8*)ptr;
    while (size--) *p++ = 0;
}

static void CopyMemory(void* dst, const void* src, U64 size) {
    U8* d = (U8*)dst;
    const U8* s = (const U8*)src;
    while (size--) *d++ = *s++;
}

// =============================================================================
// Physical Memory Access - Identity Mapping Required
// =============================================================================
//
// IMPORTANT: This hook framework requires the hypervisor to have identity-mapped
// all physical memory in its own address space (HVA == HPA).
//
// Why: We need to access guest physical pages from the hypervisor to:
//   1. Copy original page contents to shadow pages
//   2. Read/write hook trampolines
//   3. Modify code pages for inline hooks
//
// The hypervisor runs with its own CR3 (host page tables), NOT the guest's CR3.
// EPT controls GPA->HPA translation for the GUEST.
// The HYPERVISOR needs HPA->HVA translation to access those pages.
//
// Current approach: Assume HVA == HPA (identity mapping)
// Production approach would:
//   - Map specific physical pages on-demand via page tables
//   - Maintain a translation table for mapped regions
//   - Use a dedicated memory window for physical access
//
// Validation: We perform basic sanity checks by reading magic bytes when possible.

static bool ValidatePhysicalAccess(U64 physicalAddr, U64 expectedSize) {
    // Basic validation: check if address is within reasonable bounds
    // Most physical memory is below 512GB in our EPT map
    if (physicalAddr >= (512ULL * 1024 * 1024 * 1024)) {
        ERR("Physical address 0x%llx beyond 512GB - likely invalid", physicalAddr);
        return false;
    }

    // Check alignment for page access
    if (expectedSize >= 4096 && (physicalAddr & 0xFFF) != 0) {
        WARN("Physical address 0x%llx not page-aligned for %llu-byte access",
             physicalAddr, expectedSize);
    }

    return true;
}

static void* PhysicalToVirtual(U64 physicalAddr) {
    // ASSUMPTION: Identity mapping (HVA == HPA)
    // This works because the hypervisor has mapped all physical memory 1:1
    // in its own page tables (separate from guest page tables and EPT)
    return (void*)physicalAddr;
}

static bool TryReadPhysical(U64 physicalAddr, void* buffer, U64 size) {
    if (!ValidatePhysicalAccess(physicalAddr, size)) {
        return false;
    }

    void* virtualAddr = PhysicalToVirtual(physicalAddr);
    if (!virtualAddr) {
        ERR("Failed to translate physical 0x%llx to virtual", physicalAddr);
        return false;
    }

    // Attempt to read - in a full implementation, this would be wrapped
    // in exception handling to catch page faults
    CopyMemory(buffer, virtualAddr, size);
    return true;
}

static bool TryWritePhysical(U64 physicalAddr, const void* buffer, U64 size) {
    if (!ValidatePhysicalAccess(physicalAddr, size)) {
        return false;
    }

    void* virtualAddr = PhysicalToVirtual(physicalAddr);
    if (!virtualAddr) {
        ERR("Failed to translate physical 0x%llx to virtual", physicalAddr);
        return false;
    }

    // Attempt to write
    CopyMemory(virtualAddr, buffer, size);
    return true;
}

// =============================================================================
// Hook Manager Initialization
// =============================================================================

static OMBRA_STATUS ValidateIdentityMapping(EPT_STATE* ept) {
    // Test that we can access EPT structures through identity mapping
    // The EPT PML4 should be accessible at its physical address
    if (!ept || !ept->Pml4Physical) {
        ERR("Invalid EPT state for identity mapping test");
        return OMBRA_ERROR_INVALID_PARAM;
    }

    // Try to read the PML4 physical address as a virtual address
    void* pml4Va = PhysicalToVirtual(ept->Pml4Physical);
    if (!pml4Va) {
        ERR("Identity mapping failed: Cannot translate PML4 physical 0x%llx",
            ept->Pml4Physical);
        return OMBRA_ERROR_INVALID_STATE;
    }

    // Verify the content matches what we expect
    EPT_PML4E* testPml4 = (EPT_PML4E*)pml4Va;
    if (testPml4 != ept->Pml4) {
        ERR("Identity mapping verification failed: VA mismatch");
        ERR("  Expected VA: %p", ept->Pml4);
        ERR("  Identity VA:  %p", testPml4);
        return OMBRA_ERROR_INVALID_STATE;
    }

    // Verify we can read the first entry
    U64 firstEntry = testPml4[0].Value;
    if (firstEntry == 0) {
        WARN("PML4[0] is zero - EPT may not be initialized yet");
    }

    TRACE("Identity mapping validated: PML4 PA=0x%llx accessible at VA=%p",
          ept->Pml4Physical, pml4Va);

    return OMBRA_SUCCESS;
}

OMBRA_STATUS HookManagerInit(HOOK_MANAGER* mgr, EPT_STATE* ept) {
    OMBRA_STATUS status;

    if (!mgr || !ept) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    INFO("Initializing hook manager");

    // Validate that identity mapping is working
    status = ValidateIdentityMapping(ept);
    if (OMBRA_FAILED(status)) {
        ERR("Hook manager requires identity-mapped physical memory (HVA == HPA)");
        ERR("The hypervisor must map all physical memory 1:1 in its page tables");
        return status;
    }

    ZeroMemory(mgr, sizeof(HOOK_MANAGER));
    mgr->Ept = ept;
    mgr->Initialized = true;

    // Note: Shadow page pool must be allocated by caller before hooks can work
    // This requires contiguous physical memory from the driver

    INFO("Hook manager initialized (max hooks=%u)", MAX_HOOKS);
    return OMBRA_SUCCESS;
}

void HookManagerShutdown(HOOK_MANAGER* mgr) {
    if (!mgr) return;

    INFO("Shutting down hook manager (active hooks=%u)", mgr->HookCount);

    // Remove all active hooks
    for (U32 i = 0; i < MAX_HOOKS; i++) {
        if (mgr->Hooks[i].Active) {
            HookRemove(mgr, &mgr->Hooks[i]);
        }
    }

    mgr->Initialized = false;
}

// =============================================================================
// EPT Page Splitting - 1GB to 2MB
// =============================================================================
//
// Splits a 1GB large page (PDPTE) into 512 x 2MB pages (PD entries).
// This is required before we can do fine-grained 4KB hooks.

OMBRA_STATUS EptSplit1GbTo2Mb(EPT_STATE* ept, U64 guestPhysical) {
    U32 pdptIndex;
    EPT_PDPTE* pdpte;
    EPT_PDE* pd;
    U64 baseAddr;
    U32 i;

    if (!ept || !ept->Initialized) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    // Get PDPT index for this address
    pdptIndex = EPT_PDPT_INDEX(guestPhysical);
    if (pdptIndex >= EPT_ENTRIES_PER_TABLE) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    pdpte = &ept->Pdpt[pdptIndex];

    // Check if it's a 1GB page
    if (!pdpte->LargePage.LargePage) {
        TRACE("PDPTE %u is not a large page, already split?", pdptIndex);
        return OMBRA_SUCCESS;  // Already split
    }

    // We need a new page for the PD table
    // In a real implementation, this would allocate from the shadow pool
    // For now, we'll just use a pre-allocated area from EptTables

    // TODO: Allocate PD table from pool
    // For now, we store split PDs after the PDPT
    // ept->EptTables has EPT_TABLES_PAGES (512) pages
    // PML4 = page 0, PDPT = page 1, PDs = pages 2+

    if (ept->SplitPdCount >= 510) {  // Leave room for PML4 + PDPT
        ERR("No more space for PD tables");
        return OMBRA_ERROR_NO_MEMORY;
    }

    // Calculate address for new PD (after PDPT)
    U64 pdOffset = (2 + ept->SplitPdCount) * 4096;
    pd = (EPT_PDE*)((U8*)ept->Pml4 + pdOffset);
    U64 pdPhysical = ept->Pml4Physical + pdOffset;

    INFO("Splitting 1GB page at PDPT[%u] into 2MB pages (PD at 0x%llx)",
         pdptIndex, pdPhysical);

    // Get base physical address of the 1GB page
    baseAddr = pdpte->LargePage.PagePhysAddr << 30;

    // Create 512 x 2MB entries
    for (i = 0; i < EPT_ENTRIES_PER_TABLE; i++) {
        U64 physAddr = baseAddr + (i * EPT_PAGE_SIZE_2M);

        pd[i].Value = 0;
        pd[i].LargePage.Read = 1;
        pd[i].LargePage.Write = 1;
        pd[i].LargePage.Execute = 1;
        pd[i].LargePage.ExecuteUser = 1;
        pd[i].LargePage.LargePage = 1;  // 2MB large page
        pd[i].LargePage.MemoryType = EPT_MEMORY_TYPE_WB;
        pd[i].LargePage.PagePhysAddr = physAddr >> 21;  // bits 51:21
    }

    // Update PDPTE to point to new PD (no longer a large page)
    pdpte->Value = 0;
    pdpte->Pointer.Read = 1;
    pdpte->Pointer.Write = 1;
    pdpte->Pointer.Execute = 1;
    pdpte->Pointer.ExecuteUser = 1;
    pdpte->Pointer.PdPhysAddr = pdPhysical >> 12;

    ept->SplitPdCount++;

    // Invalidate EPT
    EptInvalidate(ept, INVEPT_TYPE_SINGLE_CONTEXT);

    TRACE("Split complete, now have %u split 1GB pages", ept->SplitPdCount);
    return OMBRA_SUCCESS;
}

// =============================================================================
// EPT Page Splitting - 2MB to 4KB
// =============================================================================
//
// Splits a 2MB large page (PDE) into 512 x 4KB pages (PT entries).
// This is required for per-page hook granularity.

OMBRA_STATUS EptSplit2MbTo4Kb(EPT_STATE* ept, U64 guestPhysical) {
    U32 pdptIndex, pdIndex;
    EPT_PDPTE* pdpte;
    EPT_PDE* pde;
    EPT_PTE* pt;
    U64 baseAddr;
    U32 i;

    if (!ept || !ept->Initialized) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    // First ensure the 1GB page is split
    OMBRA_STATUS status = EptSplit1GbTo2Mb(ept, guestPhysical);
    if (OMBRA_FAILED(status)) {
        return status;
    }

    // Get indices
    pdptIndex = EPT_PDPT_INDEX(guestPhysical);
    pdIndex = EPT_PD_INDEX(guestPhysical);

    // Get PDPTE (now should point to a PD)
    pdpte = &ept->Pdpt[pdptIndex];
    if (pdpte->LargePage.LargePage) {
        ERR("PDPTE is still a large page after split?");
        return OMBRA_ERROR_INVALID_STATE;
    }

    // Get PD address
    U64 pdPhysical = pdpte->Directory.PdPhysAddr << 12;

    // The PD is in our EPT tables region, which we allocated and track
    // Calculate offset from base to get virtual address
    U64 pdOffset = pdPhysical - ept->Pml4Physical;
    EPT_PDE* pd = (EPT_PDE*)((U8*)ept->Pml4 + pdOffset);

    pde = &pd[pdIndex];

    // Check if it's a 2MB page
    if (!pde->LargePage.LargePage) {
        TRACE("PDE is not a large page, already split");
        return OMBRA_SUCCESS;  // Already split
    }

    // Allocate page table
    // Similar to above, use pre-allocated space
    // For a real implementation, we'd have a proper allocator

    // Store PTs after PDs (rough estimate: 512 possible PDs, then PTs)
    // This is simplified - real implementation needs proper memory management
    if (ept->SplitPtCount >= 256) {
        ERR("No more space for PT tables");
        return OMBRA_ERROR_NO_MEMORY;
    }

    U64 ptOffset = (2 + 510 + ept->SplitPtCount) * 4096;  // After PML4, PDPT, max PDs
    pt = (EPT_PTE*)((U8*)ept->Pml4 + ptOffset);
    U64 ptPhysical = ept->Pml4Physical + ptOffset;

    INFO("Splitting 2MB page at PD[%u][%u] into 4KB pages (PT at 0x%llx)",
         pdptIndex, pdIndex, ptPhysical);

    // Get base physical address of the 2MB page
    baseAddr = pde->LargePage.PagePhysAddr << 21;

    // Create 512 x 4KB entries
    for (i = 0; i < EPT_ENTRIES_PER_TABLE; i++) {
        U64 physAddr = baseAddr + (i * EPT_PAGE_SIZE_4K);

        pt[i].Value = 0;
        pt[i].Read = 1;
        pt[i].Write = 1;
        pt[i].Execute = 1;
        pt[i].ExecuteUser = 1;
        pt[i].MemoryType = EPT_MEMORY_TYPE_WB;
        pt[i].PagePhysAddr = physAddr >> 12;
    }

    // Update PDE to point to new PT (no longer a large page)
    pde->Value = 0;
    pde->Pointer.Read = 1;
    pde->Pointer.Write = 1;
    pde->Pointer.Execute = 1;
    pde->Pointer.ExecuteUser = 1;
    pde->Pointer.PtPhysAddr = ptPhysical >> 12;

    ept->SplitPtCount++;

    // Invalidate EPT
    EptInvalidate(ept, INVEPT_TYPE_SINGLE_CONTEXT);

    TRACE("Split complete, now have %u split 2MB pages", ept->SplitPtCount);
    return OMBRA_SUCCESS;
}

// =============================================================================
// Hook Installation - EPT Execute-Only
// =============================================================================

OMBRA_STATUS HookInstallEpt(
    HOOK_MANAGER* mgr,
    U64 targetVirtual,
    U64 targetPhysical,
    void* handlerAddress,
    EPT_HOOK** outHook
) {
    EPT_HOOK* hook = NULL;
    U32 i;

    if (!mgr || !mgr->Initialized || !handlerAddress) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    INFO("Installing EPT hook at VA=0x%llx PA=0x%llx", targetVirtual, targetPhysical);

    // Find free hook slot
    for (i = 0; i < MAX_HOOKS; i++) {
        if (!mgr->Hooks[i].Active) {
            hook = &mgr->Hooks[i];
            break;
        }
    }

    if (!hook) {
        ERR("No free hook slots available");
        return OMBRA_ERROR_NO_MEMORY;
    }

    // Split EPT pages to get 4KB granularity
    OMBRA_STATUS status = EptSplit2MbTo4Kb(mgr->Ept, targetPhysical);
    if (OMBRA_FAILED(status)) {
        ERR("Failed to split EPT pages for hook");
        return status;
    }

    // Allocate shadow page
    U64 shadowPhysical;
    void* shadowVirtual = HookAllocateShadowPage(mgr, &shadowPhysical);
    if (!shadowVirtual) {
        ERR("Failed to allocate shadow page");
        return OMBRA_ERROR_NO_MEMORY;
    }

    // Copy original page content to shadow page
    // REQUIRES: Hypervisor has identity-mapped physical memory (HVA == HPA)
    U8 tempBuffer[4096];
    if (!TryReadPhysical(targetPhysical & ~0xFFFULL, tempBuffer, 4096)) {
        ERR("Failed to read target page at PA=0x%llx - not mapped in hypervisor space?",
            targetPhysical);
        HookFreeShadowPage(mgr, shadowVirtual);
        return OMBRA_ERROR_INVALID_PARAM;
    }
    CopyMemory(shadowVirtual, tempBuffer, 4096);

    // Install jump to handler at target offset in shadow page
    U32 offset = targetVirtual & 0xFFF;
    U8* hookPoint = (U8*)shadowVirtual + offset;

    // Save original bytes from the buffer we just read
    CopyMemory(hook->OriginalBytes, tempBuffer + offset, 16);

    // Write JMP to handler (64-bit absolute jump)
    // FF 25 00 00 00 00 [8-byte address]
    hookPoint[0] = 0xFF;
    hookPoint[1] = 0x25;
    hookPoint[2] = 0x00;
    hookPoint[3] = 0x00;
    hookPoint[4] = 0x00;
    hookPoint[5] = 0x00;
    *(U64*)(hookPoint + 6) = (U64)handlerAddress;
    hook->OriginalLength = 14;  // Size of our JMP

    // Setup hook structure
    hook->Magic = HOOK_MAGIC;
    hook->TargetVirtual = targetVirtual;
    hook->TargetPhysical = targetPhysical;
    hook->TargetOffset = offset;
    hook->ShadowPhysical = shadowPhysical;
    hook->ShadowVirtual = shadowVirtual;
    hook->HandlerAddress = handlerAddress;
    hook->Type = HOOK_TYPE_EPT_EXECUTE;
    hook->Active = true;
    hook->HitCount = 0;

    // Modify EPT entry for the target page
    // Execute: shadow page (with hook)
    // Read/Write: original page
    //
    // For execute-only hooks:
    // 1. Set original page to Read+Write only (no Execute)
    // 2. On execute, EPT violation triggers, we swap to shadow page
    //
    // Alternative: use mode-based execute control if available

    // Get EPT PTE for target page
    U64* pte = EptGetEntry(mgr->Ept, targetPhysical);
    if (!pte) {
        ERR("Failed to get EPT entry for target");
        hook->Active = false;
        return OMBRA_ERROR_NOT_FOUND;
    }

    // Store original PTE value
    // Then set to Execute-Only (R=0, W=0, X=1)
    // This will cause EPT violation on read/write, allowing us to show original

    // Actually, simpler approach for stealth:
    // - Execute-only for shadow page
    // - On read fault, temporarily make readable, single-step, restore

    // For now, just make the page point to shadow for all access
    // Full stealth implementation would use MTF (monitor trap flag)

    EPT_PTE* entry = (EPT_PTE*)pte;
    entry->PagePhysAddr = shadowPhysical >> 12;

    // Invalidate EPT
    EptInvalidate(mgr->Ept, INVEPT_TYPE_SINGLE_CONTEXT);

    mgr->HookCount++;

    if (outHook) {
        *outHook = hook;
    }

    INFO("EPT hook installed successfully (slot %u, count=%u)", i, mgr->HookCount);
    return OMBRA_SUCCESS;
}

// =============================================================================
// Hook Removal
// =============================================================================

OMBRA_STATUS HookRemove(HOOK_MANAGER* mgr, EPT_HOOK* hook) {
    if (!mgr || !hook || hook->Magic != HOOK_MAGIC) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    if (!hook->Active) {
        return OMBRA_SUCCESS;  // Already removed
    }

    INFO("Removing hook at VA=0x%llx", hook->TargetVirtual);

    // Restore original EPT entry
    U64* pte = EptGetEntry(mgr->Ept, hook->TargetPhysical);
    if (pte) {
        EPT_PTE* entry = (EPT_PTE*)pte;
        entry->PagePhysAddr = hook->TargetPhysical >> 12;
        EptInvalidate(mgr->Ept, INVEPT_TYPE_SINGLE_CONTEXT);
    }

    // Free shadow page
    if (hook->ShadowVirtual) {
        HookFreeShadowPage(mgr, hook->ShadowVirtual);
    }

    // Clear hook structure
    hook->Active = false;
    hook->Magic = 0;
    mgr->HookCount--;

    INFO("Hook removed (remaining=%u)", mgr->HookCount);
    return OMBRA_SUCCESS;
}

// =============================================================================
// Hook Lookup
// =============================================================================

EPT_HOOK* HookFindByPhysical(HOOK_MANAGER* mgr, U64 physicalAddress) {
    U64 pageBase = physicalAddress & ~0xFFFULL;

    for (U32 i = 0; i < MAX_HOOKS; i++) {
        EPT_HOOK* hook = &mgr->Hooks[i];
        if (hook->Active && hook->Magic == HOOK_MAGIC) {
            if ((hook->TargetPhysical & ~0xFFFULL) == pageBase ||
                (hook->ShadowPhysical & ~0xFFFULL) == pageBase) {
                return hook;
            }
        }
    }
    return NULL;
}

EPT_HOOK* HookFindByVirtual(HOOK_MANAGER* mgr, U64 virtualAddress) {
    U64 pageBase = virtualAddress & ~0xFFFULL;

    for (U32 i = 0; i < MAX_HOOKS; i++) {
        EPT_HOOK* hook = &mgr->Hooks[i];
        if (hook->Active && hook->Magic == HOOK_MAGIC) {
            if ((hook->TargetVirtual & ~0xFFFULL) == pageBase) {
                return hook;
            }
        }
    }
    return NULL;
}

// =============================================================================
// EPT Violation Handler for Hooks
// =============================================================================

bool HookHandleEptViolation(
    HOOK_MANAGER* mgr,
    U64 guestPhysical,
    U64 qualification,
    void* guestRegs
) {
    (void)guestRegs;  // For now

    if (!mgr || !mgr->Initialized) {
        return false;
    }

    // Check if this is a hooked page
    EPT_HOOK* hook = HookFindByPhysical(mgr, guestPhysical);
    if (!hook) {
        return false;  // Not our violation
    }

    bool isRead = (qualification & EPT_VIOLATION_READ) != 0;
    bool isWrite = (qualification & EPT_VIOLATION_WRITE) != 0;
    bool isExecute = (qualification & EPT_VIOLATION_EXECUTE) != 0;

    TRACE("EPT violation on hooked page: PA=0x%llx R=%d W=%d X=%d",
          guestPhysical, isRead, isWrite, isExecute);

    hook->HitCount++;

    // For a full implementation, we would:
    // 1. On execute violation: switch to shadow page, set MTF
    // 2. On read violation: switch to original page, set MTF, single-step
    // 3. On MTF exit: restore EPT mapping

    // For now, just count the hit
    return true;
}

// =============================================================================
// Shadow Page Management (Simplified)
// =============================================================================

void* HookAllocateShadowPage(HOOK_MANAGER* mgr, U64* outPhysical) {
    if (!mgr || !mgr->ShadowPool || mgr->ShadowPoolUsed >= mgr->ShadowPoolSize) {
        return NULL;
    }

    U32 pageIndex = mgr->ShadowPoolUsed++;
    void* page = (U8*)mgr->ShadowPool + (pageIndex * 4096);
    *outPhysical = mgr->ShadowPoolPhysical + (pageIndex * 4096);

    return page;
}

void HookFreeShadowPage(HOOK_MANAGER* mgr, void* page) {
    (void)mgr;
    (void)page;
    // Simplified - real implementation would track free pages
    // For now, shadow pages are not reclaimed
}

// =============================================================================
// Hook Installation - Inline Hook (JMP)
// =============================================================================
//
// Inline hooks use EPT execute-only pages for stealth:
// - Execute: runs from shadow page (contains JMP to handler)
// - Read: sees original page (no JMP visible)
//
// This defeats signature scanning and code integrity checks.

OMBRA_STATUS HookInstallInline(
    HOOK_MANAGER* mgr,
    U64 targetVirtual,
    U64 targetPhysical,
    void* handlerAddress,
    EPT_HOOK** outHook
) {
    EPT_HOOK* hook = NULL;
    U32 i;

    if (!mgr || !mgr->Initialized || !handlerAddress) {
        return OMBRA_ERROR_INVALID_PARAM;
    }

    if (!mgr->ShadowPool) {
        ERR("Shadow pool not allocated");
        return OMBRA_ERROR_INVALID_STATE;
    }

    INFO("Installing inline hook at VA=0x%llx PA=0x%llx", targetVirtual, targetPhysical);

    // Find free hook slot
    for (i = 0; i < MAX_HOOKS; i++) {
        if (!mgr->Hooks[i].Active) {
            hook = &mgr->Hooks[i];
            break;
        }
    }

    if (!hook) {
        ERR("No free hook slots available (max=%u)", MAX_HOOKS);
        return OMBRA_ERROR_NO_MEMORY;
    }

    // Split EPT pages down to 4KB granularity for precise hooking
    OMBRA_STATUS status = EptSplit2MbTo4Kb(mgr->Ept, targetPhysical);
    if (OMBRA_FAILED(status)) {
        ERR("Failed to split EPT pages for inline hook: 0x%x", status);
        return status;
    }

    // Allocate shadow page for hook code
    U64 shadowPhysical;
    void* shadowVirtual = HookAllocateShadowPage(mgr, &shadowPhysical);
    if (!shadowVirtual) {
        ERR("Failed to allocate shadow page from pool");
        return OMBRA_ERROR_NO_MEMORY;
    }

    // Copy entire original page to shadow page
    // This preserves all code in the page except our hook point
    // REQUIRES: Hypervisor has identity-mapped physical memory (HVA == HPA)
    U64 targetPagePhys = targetPhysical & ~0xFFFULL;
    U8 tempBuffer[4096];
    if (!TryReadPhysical(targetPagePhys, tempBuffer, 4096)) {
        ERR("Failed to read target page at PA=0x%llx - not mapped in hypervisor space?",
            targetPagePhys);
        HookFreeShadowPage(mgr, shadowVirtual);
        ZeroMemory(hook, sizeof(EPT_HOOK));
        return OMBRA_ERROR_INVALID_PARAM;
    }
    CopyMemory(shadowVirtual, tempBuffer, 4096);

    // Calculate hook point offset within the page
    U32 offset = (U32)(targetVirtual & 0xFFF);
    U8* hookPoint = (U8*)shadowVirtual + offset;

    // Save original bytes from the buffer we just read
    CopyMemory(hook->OriginalBytes, tempBuffer + offset, 16);

    // Construct absolute JMP instruction to handler
    // Format: mov rax, <handler>; jmp rax
    // Encoding:
    //   48 B8 [8-byte address]   ; mov rax, immediate64
    //   FF E0                     ; jmp rax
    // Total: 12 bytes

    hookPoint[0] = 0x48;  // REX.W prefix
    hookPoint[1] = 0xB8;  // MOV RAX, imm64
    *(U64*)(hookPoint + 2) = (U64)handlerAddress;  // 8-byte handler address
    hookPoint[10] = 0xFF;  // JMP r/m64
    hookPoint[11] = 0xE0;  // ModRM: register rax

    hook->OriginalLength = 12;  // Size of our JMP stub

    // Initialize hook structure
    hook->Magic = HOOK_MAGIC;
    hook->TargetVirtual = targetVirtual;
    hook->TargetPhysical = targetPhysical & ~0xFFFULL;  // Page-aligned
    hook->TargetOffset = offset;
    hook->ShadowPhysical = shadowPhysical;
    hook->ShadowVirtual = shadowVirtual;
    hook->HandlerAddress = handlerAddress;
    hook->TrampolineAddress = NULL;  // TODO: Create trampoline for calling original
    hook->Type = HOOK_TYPE_INLINE;
    hook->Active = true;
    hook->Executing = false;
    hook->HitCount = 0;
    hook->CpuMask = 0;  // All CPUs
    hook->Next = NULL;

    // Configure EPT for execute-only shadow page stealth:
    //
    // We need TWO EPT entries conceptually (hardware limitation workaround):
    // 1. For execute: point to shadow page with R=0, W=0, X=1
    // 2. For read/write: point to original page
    //
    // Since we can't have both simultaneously, we use EPT violations:
    // - Set entry to execute-only shadow (R=0, W=0, X=1, points to shadow)
    // - On read/write violation, temporarily switch to original, MTF, restore
    //
    // This requires MTF (Monitor Trap Flag) support for single-stepping.

    U64* pte = EptGetEntry(mgr->Ept, targetPhysical);
    if (!pte) {
        ERR("Failed to get EPT PTE for PA=0x%llx", targetPhysical);
        HookFreeShadowPage(mgr, shadowVirtual);
        ZeroMemory(hook, sizeof(EPT_HOOK));
        return OMBRA_ERROR_NOT_FOUND;
    }

    EPT_PTE* entry = (EPT_PTE*)pte;

    // Store original PTE configuration (for unhooking)
    // In full implementation, we'd save this properly
    // U64 originalPte = entry->Value;

    // Configure EPT PTE for execute-only stealth:
    // - Point to shadow page (contains hook)
    // - Execute: allowed (X=1)
    // - Read: denied (R=0) - will cause EPT violation
    // - Write: denied (W=0) - will cause EPT violation
    //
    // On EPT violation from read/write, HookHandleEptViolation() will:
    // 1. Switch PTE to original page with R=1, W=1, X=0
    // 2. Enable MTF (monitor trap flag)
    // 3. On MTF exit, restore execute-only shadow mapping

    entry->Value = 0;
    entry->Read = 0;          // Deny read - force violation
    entry->Write = 0;         // Deny write - force violation
    entry->Execute = 1;       // Allow execute from shadow
    entry->ExecuteUser = 1;   // User-mode execute allowed
    entry->MemoryType = EPT_MEMORY_TYPE_WB;
    entry->PagePhysAddr = shadowPhysical >> 12;  // Point to shadow page

    // Invalidate EPT TLB to activate new mapping immediately
    EptInvalidate(mgr->Ept, INVEPT_TYPE_SINGLE_CONTEXT);

    mgr->HookCount++;

    if (outHook) {
        *outHook = hook;
    }

    INFO("Inline hook installed (slot=%u, total=%u, shadow=0x%llx)",
         i, mgr->HookCount, shadowPhysical);

    return OMBRA_SUCCESS;
}

// =============================================================================
// Hook Enable/Disable
// =============================================================================

OMBRA_STATUS HookEnable(EPT_HOOK* hook) {
    if (!hook || hook->Magic != HOOK_MAGIC) {
        return OMBRA_ERROR_INVALID_PARAM;
    }
    hook->Active = true;
    return OMBRA_SUCCESS;
}

OMBRA_STATUS HookDisable(EPT_HOOK* hook) {
    if (!hook || hook->Magic != HOOK_MAGIC) {
        return OMBRA_ERROR_INVALID_PARAM;
    }
    hook->Active = false;
    return OMBRA_SUCCESS;
}
